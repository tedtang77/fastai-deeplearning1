{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import utils_ted\n",
    "from utils_ted import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't really looked into the detail of how this works yet - so this is provided for self-study for those who are interested. We'll look at it closely next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path=get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path, encoding='utf8').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are thinkers who believe in the saints.\n",
      "\n",
      "\n",
      "144\n",
      "\n",
      "It stands to reason that this sketch of the saint, made upon the model\n",
      "of the whole species, can be confronted with many opposing sketches that\n",
      "would create a more agreeable impression. There are certain exceptions\n",
      "among the species who distinguish themselves either by especial\n",
      "gentleness or especial humanity, and perhaps by the strength of their\n",
      "own personality. Others are in the highest degree fascinating because\n",
      "certain of their delusions shed a particular glow over their whole\n",
      "being, as is the case with the founder of christianity who took himself\n",
      "for the only begotten son of God and hence felt himself sinless; so that\n",
      "through his imagination--that should not be too harshly judged since the\n",
      "whole of antiquity swarmed with sons of god--he attained the same goal,\n",
      "the sense of complete sinlessness, complete irresponsibility, that can\n",
      "now be attained by every individual through science.--In the same manner\n",
      "I have viewed the saints of India who occupy an intermediate station\n",
      "between the christian saints and the Greek philosophers and hence are\n",
      "not to be regarded as a pure type. Knowledge and science--as far as they\n",
      "existed--and superiority to the rest of mankind by logical discipline\n",
      "and training of the intellectual powers were insisted upon by the\n",
      "Buddhists as essential to sanctity, just as they were denounced by the\n",
      "christian world as the indications of sinfulness.\n"
     ]
    }
   ],
   "source": [
    "!tail {path} -n25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars : 58\n"
     ]
    }
   ],
   "source": [
    "print(\"total chars : %s\" % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars.insert(0, '/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/n\\n !\"\\'(),-.0123456789:;=?[]_abcdefghijklmnopqrstuvwxyz'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(chars[0:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_indices = {c:i for i, c in enumerate(chars)}\n",
    "indices_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_idxs = [char_indices[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43, 45, 32, 33, 28, 30, 32, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(text_idxs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface\\n\\n\\nsupposing that truth is a woman--what then? is there not gro'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[idx] for idx in text_idxs[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 40\n",
    "sentences_list = []\n",
    "next_chars_list = []\n",
    "for i in range(0, (len(text_idxs) - maxlen + 1)):\n",
    "    sentences_list.append(text_idxs[i: i+maxlen])\n",
    "    next_chars_list.append(text_idxs[i+1: i+maxlen+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 600854\n"
     ]
    }
   ],
   "source": [
    "print(\"nb sequences:\", len(sentences_list))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(text_idxs))\n",
    "print(text_idxs[:3])\n",
    "print(text_idxs[-3:])\n",
    "\n",
    "print(sentences_list[0])\n",
    "print(next_chars_list[0])\n",
    "print(sentences_list[-1])\n",
    "print(next_chars_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = np.array(sentences_list[:-2])\n",
    "next_chars = np.array(next_chars_list[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600852, 40) (600852, 40)\n"
     ]
    }
   ],
   "source": [
    "print(sentences.shape, next_chars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras 2.0 release notes](https://github.com/fchollet/keras/wiki/Keras-2.0-release-notes)\n",
    "\n",
    "```\n",
    "Recurrent layers\n",
    "    output_dim -> units\n",
    "    init -> kernel_initializer\n",
    "    inner_init -> recurrent_initializer\n",
    "    added argument bias_initializer\n",
    "    W_regularizer -> kernel_regularizer\n",
    "    b_regularizer -> bias_regularizer\n",
    "    added arguments kernel_constraint, recurrent_constraint, bias_constraint\n",
    "    dropout_W -> dropout\n",
    "    dropout_U -> recurrent_dropout\n",
    "    consume_less -> implementation. String values have been replaced with integers: implementation 0 (default), 1 or 2.\n",
    "    LSTM only: the argument forget_bias_init has been removed. Instead there is a boolean argument unit_forget_bias, defaulting to True.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(512, return_sequences=True, implementation=1, input_shape=(None, 24))`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=maxlen),\n",
    "    BatchNormalization(),\n",
    "    #LSTM(512, input_dim=n_fac, return_sequences=True, \n",
    "    #     dropout=0.2, recurrent_dropout=0.2, implementation=1),\n",
    "    LSTM(512, input_dim=n_fac, return_sequences=True, implementation=1),\n",
    "    #Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    #LSTM(512, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, implementation=1),\n",
    "    LSTM(512, return_sequences=True, implementation=1),\n",
    "    #Dropout(0.2),\n",
    "    BatchNormalization(),\n",
    "    TimeDistributed(Dense(vocab_size)),\n",
    "    Activation('softmax')    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_example():\n",
    "    seed_string=\"ethics is a basic foundation of all that\"\n",
    "    for i in range(200):\n",
    "        x = np.array([char_indices[c] for c in seed_string[-40:]])[np.newaxis,:]\n",
    "        preds = np.squeeze(model.predict(x, verbose=0))[-1]\n",
    "        preds = preds/np.sum(preds)\n",
    "        next_char = choice(chars, p=preds)\n",
    "        seed_string = seed_string + next_char\n",
    "    print(seed_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[45],\n",
       "        [32],\n",
       "        [33],\n",
       "        ..., \n",
       "        [40],\n",
       "        [28],\n",
       "        [41]],\n",
       "\n",
       "       [[32],\n",
       "        [33],\n",
       "        [28],\n",
       "        ..., \n",
       "        [28],\n",
       "        [41],\n",
       "        [ 9]],\n",
       "\n",
       "       [[33],\n",
       "        [28],\n",
       "        [30],\n",
       "        ..., \n",
       "        [41],\n",
       "        [ 9],\n",
       "        [ 9]],\n",
       "\n",
       "       ..., \n",
       "       [[36],\n",
       "        [28],\n",
       "        [41],\n",
       "        ..., \n",
       "        [39],\n",
       "        [41],\n",
       "        [32]],\n",
       "\n",
       "       [[28],\n",
       "        [41],\n",
       "        [ 2],\n",
       "        ..., \n",
       "        [41],\n",
       "        [32],\n",
       "        [46]],\n",
       "\n",
       "       [[41],\n",
       "        [ 2],\n",
       "        [50],\n",
       "        ..., \n",
       "        [32],\n",
       "        [46],\n",
       "        [46]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(next_chars,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33 48 36 37 31 47  3 37 47  3 29  3 30 29 47 37 31  3 34 43 49 42 32 29\n",
      "  48 37 43 42  3 43 34  3 29 40 40  3 48 36 29 48]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a and p must have same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-01749e406beb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-34-73ee8a8298e9>\u001b[0m in \u001b[0;36mprint_example\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mnext_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mseed_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed_string\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnext_char\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a and p must have same size"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 1771s - loss: 1.2742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8af6faba8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sentences, np.expand_dims(next_chars,-1), batch_size=64, epochs=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ethics is a basic foundation of all that there is a rank is political religion, and\n",
      "morality and rigour spirit renders the\n",
      "causes of\n",
      "others. they can find ourselves?\n",
      "\n",
      "144. what does it not follow growth, as anything\n",
      "else!\n",
      "but\n",
      "does not thus\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('../data/char_rnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
