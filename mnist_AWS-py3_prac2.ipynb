{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a quick tour for going end-to-end model building and tuning for MNIST dataset\n",
    "## Adding Pseudo Labeling Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import utils_ted\n",
    "from utils_ted import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember this step is necessary for MNIST data\n",
    "X_train = np.expand_dims(X_train, 1) # np.expand_dims(X_train, 3) # for channel last case\n",
    "X_test = np.expand_dims(X_test, 1) # np.expand_dims(X_test, 3) # for channel last case\n",
    "y_train = y_train.reshape((-1, 1))\n",
    "y_test = y_test.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((60000, 1, 28, 28), (60000, 1)), ((10000, 1, 28, 28), (10000, 1)))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5]\n",
      " [0]\n",
      " [4]\n",
      " [1]\n",
      " [9]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### turn y_train, y_test from classes into labels by onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def norm_input(x): return (x - mean_px) / std_px  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Tune Model (to overfitting)\n",
    "** tune it to overfitting to make sure that your model is complex enough to work well **\n",
    "\n",
    "** after making it, then we can tune it to reduce overfitting for the next steps by different methods **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(input_shape=input_shape),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 5s - loss: 0.4251 - acc: 0.8760 - val_loss: 0.3051 - val_acc: 0.9147\n",
      "Epoch 2/2\n",
      " - 4s - loss: 0.2941 - acc: 0.9168 - val_loss: 0.2884 - val_acc: 0.9183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86e58300b8>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=2, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 4s - loss: 0.2795 - acc: 0.9206 - val_loss: 0.2904 - val_acc: 0.9235\n",
      "Epoch 2/5\n",
      " - 4s - loss: 0.2716 - acc: 0.9237 - val_loss: 0.2949 - val_acc: 0.9217\n",
      "Epoch 3/5\n",
      " - 4s - loss: 0.2660 - acc: 0.9253 - val_loss: 0.2904 - val_acc: 0.9235\n",
      "Epoch 4/5\n",
      " - 4s - loss: 0.2617 - acc: 0.9276 - val_loss: 0.2943 - val_acc: 0.9214\n",
      "Epoch 5/5\n",
      " - 4s - loss: 0.2576 - acc: 0.9283 - val_loss: 0.2980 - val_acc: 0.9217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86ec71ee80>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=5, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG style model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn():\n",
    "    model = Sequential([\n",
    "        BatchNormalization(input_shape=input_shape),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 27s - loss: 0.0916 - acc: 0.9724 - val_loss: 0.0377 - val_acc: 0.9877\n",
      "Epoch 2/2\n",
      " - 24s - loss: 0.0365 - acc: 0.9883 - val_loss: 0.0296 - val_acc: 0.9911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86e78b0ac8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=2, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 24s - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0285 - val_acc: 0.9918\n",
      "Epoch 2/5\n",
      " - 24s - loss: 0.0172 - acc: 0.9947 - val_loss: 0.0288 - val_acc: 0.9924\n",
      "Epoch 3/5\n",
      " - 24s - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0256 - val_acc: 0.9924\n",
      "Epoch 4/5\n",
      " - 24s - loss: 0.0130 - acc: 0.9955 - val_loss: 0.0265 - val_acc: 0.9924\n",
      "Epoch 5/5\n",
      " - 24s - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0266 - val_acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86e194c7b8>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=5, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm + Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, height_shift_range=0.08, \n",
    "                         shear_range=0.3, zoom_range=0.08)\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen_aug.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model_bn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 29s - loss: 0.1669 - acc: 0.9480 - val_loss: 0.0269 - val_acc: 0.9911\n",
      "Epoch 2/2\n",
      " - 24s - loss: 0.0710 - acc: 0.9772 - val_loss: 0.0324 - val_acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86e0dbc668>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=2, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 24s - loss: 0.0573 - acc: 0.9819 - val_loss: 0.0273 - val_acc: 0.9913\n",
      "Epoch 2/5\n",
      " - 24s - loss: 0.0510 - acc: 0.9841 - val_loss: 0.0182 - val_acc: 0.9938\n",
      "Epoch 3/5\n",
      " - 24s - loss: 0.0472 - acc: 0.9848 - val_loss: 0.0190 - val_acc: 0.9938\n",
      "Epoch 4/5\n",
      " - 25s - loss: 0.0425 - acc: 0.9865 - val_loss: 0.0186 - val_acc: 0.9946\n",
      "Epoch 5/5\n",
      " - 25s - loss: 0.0403 - acc: 0.9872 - val_loss: 0.0163 - val_acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86e183c048>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=5, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm + Data Augmentation + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn_dropout(p):\n",
    "    model = Sequential([\n",
    "        BatchNormalization(input_shape=input_shape),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model_bn_dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 28s - loss: 0.2252 - acc: 0.9327 - val_loss: 0.0298 - val_acc: 0.9901\n",
      "Epoch 2/2\n",
      " - 25s - loss: 0.0960 - acc: 0.9708 - val_loss: 0.0316 - val_acc: 0.9896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86db4e80f0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=2, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 25s - loss: 0.0770 - acc: 0.9772 - val_loss: 0.0235 - val_acc: 0.9922\n",
      "Epoch 2/8\n",
      " - 25s - loss: 0.0660 - acc: 0.9794 - val_loss: 0.0192 - val_acc: 0.9937\n",
      "Epoch 3/8\n",
      " - 25s - loss: 0.0607 - acc: 0.9817 - val_loss: 0.0196 - val_acc: 0.9932\n",
      "Epoch 4/8\n",
      " - 25s - loss: 0.0550 - acc: 0.9824 - val_loss: 0.0214 - val_acc: 0.9924\n",
      "Epoch 5/8\n",
      " - 24s - loss: 0.0537 - acc: 0.9832 - val_loss: 0.0149 - val_acc: 0.9958\n",
      "Epoch 6/8\n",
      " - 25s - loss: 0.0479 - acc: 0.9851 - val_loss: 0.0192 - val_acc: 0.9935\n",
      "Epoch 7/8\n",
      " - 25s - loss: 0.0501 - acc: 0.9851 - val_loss: 0.0158 - val_acc: 0.9952\n",
      "Epoch 8/8\n",
      " - 25s - loss: 0.0463 - acc: 0.9859 - val_loss: 0.0184 - val_acc: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f86d9c87f60>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=8, verbose=2,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_dropout(0.5)\n",
    "    model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=1, verbose=0,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=4, verbose=0,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=8, verbose=0,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, steps_per_epoch=ceil(batches.n/batches.batch_size), epochs=12, verbose=0,\n",
    "                validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/mnist/'\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.makedirs(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, mdl in enumerate(models):\n",
    "    mdl.save_weights(model_path+'cnn-mnist-aws-prac2'+ str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Weights\n",
    "models = []\n",
    "for i in range(6):\n",
    "    model = get_model_bn_dropout(0.5)\n",
    "    model.load_weights(model_path+'cnn-mnist-aws-prac2'+ str(i)+'.h5')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  256/10000 [..............................] - ETA: 35s\n",
      "  768/10000 [=>............................] - ETA: 11s\n",
      " 1280/10000 [==>...........................] - ETA: 7s \n",
      " 1792/10000 [====>.........................] - ETA: 5s\n",
      " 2304/10000 [=====>........................] - ETA: 3s\n",
      " 2816/10000 [=======>......................] - ETA: 3s\n",
      " 3584/10000 [=========>....................] - ETA: 2s\n",
      " 4352/10000 [============>.................] - ETA: 1s\n",
      " 5120/10000 [==============>...............] - ETA: 1s\n",
      " 5888/10000 [================>.............] - ETA: 1s\n",
      " 6656/10000 [==================>...........] - ETA: 0s\n",
      " 7424/10000 [=====================>........] - ETA: 0s\n",
      " 8192/10000 [=======================>......] - ETA: 0s\n",
      " 8960/10000 [=========================>....] - ETA: 0s\n",
      " 9728/10000 [============================>.] - ETA: 0s\n",
      "10000/10000 [==============================] - 2s 179us/step\n",
      "\n",
      "  256/10000 [..............................] - ETA: 31s\n",
      " 1024/10000 [==>...........................] - ETA: 7s \n",
      " 1792/10000 [====>.........................] - ETA: 4s\n",
      " 2560/10000 [======>.......................] - ETA: 2s\n",
      " 3328/10000 [========>.....................] - ETA: 2s\n",
      " 4096/10000 [===========>..................] - ETA: 1s\n",
      " 4864/10000 [=============>................] - ETA: 1s\n",
      " 5632/10000 [===============>..............] - ETA: 0s\n",
      " 6400/10000 [==================>...........] - ETA: 0s\n",
      " 7168/10000 [====================>.........] - ETA: 0s\n",
      " 7936/10000 [======================>.......] - ETA: 0s\n",
      " 8704/10000 [=========================>....] - ETA: 0s\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "10000/10000 [==============================] - 2s 156us/step\n",
      "\n",
      "  256/10000 [..............................] - ETA: 33s\n",
      " 1024/10000 [==>...........................] - ETA: 8s \n",
      " 1792/10000 [====>.........................] - ETA: 4s\n",
      " 2560/10000 [======>.......................] - ETA: 3s\n",
      " 3328/10000 [========>.....................] - ETA: 2s\n",
      " 4096/10000 [===========>..................] - ETA: 1s\n",
      " 4864/10000 [=============>................] - ETA: 1s\n",
      " 5632/10000 [===============>..............] - ETA: 0s\n",
      " 6400/10000 [==================>...........] - ETA: 0s\n",
      " 7168/10000 [====================>.........] - ETA: 0s\n",
      " 7936/10000 [======================>.......] - ETA: 0s\n",
      " 8704/10000 [=========================>....] - ETA: 0s\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "10000/10000 [==============================] - 2s 162us/step\n",
      "\n",
      "  256/10000 [..............................] - ETA: 30s\n",
      " 1024/10000 [==>...........................] - ETA: 7s \n",
      " 1792/10000 [====>.........................] - ETA: 4s\n",
      " 2560/10000 [======>.......................] - ETA: 2s\n",
      " 3328/10000 [========>.....................] - ETA: 2s\n",
      " 4096/10000 [===========>..................] - ETA: 1s\n",
      " 4864/10000 [=============>................] - ETA: 1s\n",
      " 5632/10000 [===============>..............] - ETA: 0s\n",
      " 6400/10000 [==================>...........] - ETA: 0s\n",
      " 7168/10000 [====================>.........] - ETA: 0s\n",
      " 7936/10000 [======================>.......] - ETA: 0s\n",
      " 8704/10000 [=========================>....] - ETA: 0s\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "10000/10000 [==============================] - 2s 154us/step\n",
      "\n",
      "  256/10000 [..............................] - ETA: 32s\n",
      " 1024/10000 [==>...........................] - ETA: 8s \n",
      " 1792/10000 [====>.........................] - ETA: 4s\n",
      " 2560/10000 [======>.......................] - ETA: 3s\n",
      " 3328/10000 [========>.....................] - ETA: 2s\n",
      " 4096/10000 [===========>..................] - ETA: 1s\n",
      " 4864/10000 [=============>................] - ETA: 1s\n",
      " 5632/10000 [===============>..............] - ETA: 0s\n",
      " 6400/10000 [==================>...........] - ETA: 0s\n",
      " 7168/10000 [====================>.........] - ETA: 0s\n",
      " 7936/10000 [======================>.......] - ETA: 0s\n",
      " 8704/10000 [=========================>....] - ETA: 0s\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "10000/10000 [==============================] - 2s 161us/step\n",
      "\n",
      "  256/10000 [..............................] - ETA: 30s\n",
      " 1024/10000 [==>...........................] - ETA: 7s \n",
      " 1792/10000 [====>.........................] - ETA: 4s\n",
      " 2560/10000 [======>.......................] - ETA: 2s\n",
      " 3328/10000 [========>.....................] - ETA: 2s\n",
      " 4096/10000 [===========>..................] - ETA: 1s\n",
      " 4864/10000 [=============>................] - ETA: 1s\n",
      " 5632/10000 [===============>..............] - ETA: 0s\n",
      " 6400/10000 [==================>...........] - ETA: 0s\n",
      " 7168/10000 [====================>.........] - ETA: 0s\n",
      " 7936/10000 [======================>.......] - ETA: 0s\n",
      " 8704/10000 [=========================>....] - ETA: 0s\n",
      " 9472/10000 [===========================>..] - ETA: 0s\n",
      "10000/10000 [==============================] - 2s 153us/step\n"
     ]
    }
   ],
   "source": [
    "evals = np.array([mdl.evaluate(X_test, y_test, batch_size=batch_size*4, verbose=2) for mdl in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01354901,  0.99576667])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([mdl.predict(X_test, batch_size=batch_size*4, verbose=2) for mdl in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_accuracy(test_labels, preds):\n",
    "    #keras.metrics.categorical_accuracy(y_test, avg_preds).eval()\n",
    "    \n",
    "    # https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\n",
    "    with sess.as_default():\n",
    "        eval_result = accuracy(test_labels, preds).eval()\n",
    "    return eval_result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99720001"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(y_test, avg_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixIterator(object):\n",
    "    \n",
    "    def __init__(self, iters):\n",
    "        self.iters = iters\n",
    "        self.n = sum([itr.n for itr in self.iters])\n",
    "        self.batch_size = sum([itr.batch_size for itr in self.iters])\n",
    "    \n",
    "    def reset(self):\n",
    "        for itr in self.iters: itr.reset()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self, *args, **kwargs):\n",
    "        nexts = [next(itr) for itr in self.iters]\n",
    "        n0 = np.concatenate([n[0] for n in nexts])\n",
    "        n1 = np.concatenate([n[1] for n in nexts])\n",
    "        return (n0, n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10), (10000, 10))"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_preds.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_aug = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, height_shift_range=0.08, \n",
    "                         shear_range=0.3, zoom_range=0.08)\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen_aug.flow(X_train, y_train, batch_size=batch_size)\n",
    "pseudolabel_batches = gen.flow(X_test, avg_preds, batch_size=batch_size//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_pseudolabel_batches = MixIterator([batches, pseudolabel_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 80)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_pseudolabel_batches.n, mix_pseudolabel_batches.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model_bn_dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 30s - loss: 0.1930 - acc: 0.9421 - val_loss: 0.0205 - val_acc: 0.9930\n",
      "Epoch 2/2\n",
      " - 25s - loss: 0.0790 - acc: 0.9764 - val_loss: 0.0147 - val_acc: 0.9947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f868c7532b0>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(mix_pseudolabel_batches, steps_per_epoch=ceil(mix_pseudolabel_batches.n/mix_pseudolabel_batches.batch_size), \n",
    "                    epochs=2, verbose=2,\n",
    "                    validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 25s - loss: 0.0637 - acc: 0.9808 - val_loss: 0.0159 - val_acc: 0.9951\n",
      "Epoch 2/8\n",
      " - 25s - loss: 0.0558 - acc: 0.9834 - val_loss: 0.0138 - val_acc: 0.9959\n",
      "Epoch 3/8\n",
      " - 26s - loss: 0.0524 - acc: 0.9844 - val_loss: 0.0169 - val_acc: 0.9952\n",
      "Epoch 4/8\n",
      " - 26s - loss: 0.0510 - acc: 0.9855 - val_loss: 0.0203 - val_acc: 0.9939\n",
      "Epoch 5/8\n",
      " - 26s - loss: 0.0440 - acc: 0.9868 - val_loss: 0.0124 - val_acc: 0.9962\n",
      "Epoch 6/8\n",
      " - 25s - loss: 0.0456 - acc: 0.9872 - val_loss: 0.0147 - val_acc: 0.9957\n",
      "Epoch 7/8\n",
      " - 25s - loss: 0.0405 - acc: 0.9885 - val_loss: 0.0139 - val_acc: 0.9959\n",
      "Epoch 8/8\n",
      " - 25s - loss: 0.0424 - acc: 0.9878 - val_loss: 0.0147 - val_acc: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f868b801dd8>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(mix_pseudolabel_batches, steps_per_epoch=ceil(mix_pseudolabel_batches.n/mix_pseudolabel_batches.batch_size), \n",
    "                    epochs=8, verbose=2,\n",
    "                    validation_data=test_batches, validation_steps=(test_batches.n/test_batches.batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo-labeling: Finally after you are confident, you even can add validation dataset into Pseudo Labeling and hope it would improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
