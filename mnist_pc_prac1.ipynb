{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a quick tour for going end-to-end model building and tuning for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remember this step is necessary for MNIST data\n",
    "X_train = np.expand_dims(X_train, 1) # np.expand_dims(X_train, 3) # for channel last case\n",
    "X_test = np.expand_dims(X_test, 1) # np.expand_dims(X_test, 3) # for channel last case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x181920f1390>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181920b4470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### turn y_train, y_test from classes into labels by onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = onehot(y_train)\n",
    "y_test = onehot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33.31842, 78.56749)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_px, std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x): return (x - mean_px) / std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Tune Model (to overfitting)\n",
    "** tune it to overfitting to make sure that your model is complex enough to work well **\n",
    "\n",
    "** after making it, then we can tune it to reduce overfitting for the next steps by different methods **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lin_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Tip: Procedures to tune learning rate\n",
    "**1. When running, always start doing 1 epoch with a fairly low learning rate. Keras gives a good default learning rate, 0.001, so I always start with default learning rate. And then you can tune into you own learning rate.**\n",
    "\n",
    "**2. Once you get started, you can raise your learning rate to run several epochs with learning rate, 0.1.**\n",
    "\n",
    "**3. After you make it, you can start tuning your learning rate to like 0.01 to run more epochs until you get to overfitting.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_2 (Lambda)            (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(K.get_value(lm.optimizer.lr))\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3750/3750 [==============================] - 7s - loss: 0.3728 - acc: 0.8921 - val_loss: 0.3037 - val_acc: 0.9124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818d61bcc0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=1, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lm.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3750/3750 [==============================] - 7s - loss: 0.3086 - acc: 0.9134 - val_loss: 0.3155 - val_acc: 0.9138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181800c5080>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=1, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 6s - loss: 0.2909 - acc: 0.9195 - val_loss: 0.2949 - val_acc: 0.9196\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2872 - acc: 0.9197 - val_loss: 0.3273 - val_acc: 0.9085\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2831 - acc: 0.9217 - val_loss: 0.3106 - val_acc: 0.9159\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2827 - acc: 0.9222 - val_loss: 0.2957 - val_acc: 0.9193\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 6s - loss: 0.2791 - acc: 0.9229 - val_loss: 0.3335 - val_acc: 0.9101\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2784 - acc: 0.9235 - val_loss: 0.3272 - val_acc: 0.9141\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2786 - acc: 0.9241 - val_loss: 0.3147 - val_acc: 0.9188\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2749 - acc: 0.9237 - val_loss: 0.3272 - val_acc: 0.9127\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2745 - acc: 0.9250 - val_loss: 0.3029 - val_acc: 0.9170\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 7s - loss: 0.2727 - acc: 0.9240 - val_loss: 0.3148 - val_acc: 0.9190\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181800c5198>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=10, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='softmax'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_3 (Lambda)            (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3750/3750 [==============================] - 45s - loss: 1.0174 - acc: 0.8027 - val_loss: 0.5340 - val_acc: 0.8293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818d764ef0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=1, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 46s - loss: 0.4290 - acc: 0.8540 - val_loss: 0.4139 - val_acc: 0.8661\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 44s - loss: 0.3999 - acc: 0.8636 - val_loss: 0.4222 - val_acc: 0.8412\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 46s - loss: 0.3839 - acc: 0.8716 - val_loss: 0.4078 - val_acc: 0.8582\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 44s - loss: 0.3657 - acc: 0.8792 - val_loss: 0.3848 - val_acc: 0.8834\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 45s - loss: 0.3453 - acc: 0.8948 - val_loss: 0.3544 - val_acc: 0.9025\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 44s - loss: 0.3141 - acc: 0.9136 - val_loss: 0.2936 - val_acc: 0.9280\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 49s - loss: 0.2579 - acc: 0.9363 - val_loss: 0.2548 - val_acc: 0.9403\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 72s - loss: 0.2312 - acc: 0.9445 - val_loss: 0.2774 - val_acc: 0.9326\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 48s - loss: 0.2177 - acc: 0.9471 - val_loss: 0.2388 - val_acc: 0.9436\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 48s - loss: 0.2090 - acc: 0.9503 - val_loss: 0.2430 - val_acc: 0.9442\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818d903160>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=10, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 49s - loss: 0.2020 - acc: 0.9520 - val_loss: 0.2193 - val_acc: 0.9494\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 46s - loss: 0.1955 - acc: 0.9530 - val_loss: 0.2197 - val_acc: 0.9506\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 47s - loss: 0.1867 - acc: 0.9560 - val_loss: 0.2249 - val_acc: 0.9505\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 72s - loss: 0.1828 - acc: 0.9569 - val_loss: 0.2315 - val_acc: 0.9488\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 43s - loss: 0.1765 - acc: 0.9592 - val_loss: 0.2268 - val_acc: 0.9477\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 43s - loss: 0.1727 - acc: 0.9608 - val_loss: 0.2162 - val_acc: 0.9502\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 44s - loss: 0.1683 - acc: 0.9619 - val_loss: 0.2229 - val_acc: 0.9517\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 70s - loss: 0.1636 - acc: 0.9630 - val_loss: 0.2138 - val_acc: 0.9521\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 47s - loss: 0.1599 - acc: 0.9642 - val_loss: 0.2326 - val_acc: 0.9509\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 53s - loss: 0.1550 - acc: 0.9648 - val_loss: 0.2160 - val_acc: 0.9561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818dc29710>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=10, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic 'VGG-style' CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        Conv2D(32, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 26, 26)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 24, 24)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 10, 10)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 8, 8)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 594,922\n",
      "Trainable params: 594,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3750/3750 [==============================] - 685s - loss: 0.0951 - acc: 0.9702 - val_loss: 0.0341 - val_acc: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818f3720f0>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=1, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 704s - loss: 0.0395 - acc: 0.9880 - val_loss: 0.0493 - val_acc: 0.9873\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 1024s - loss: 0.0277 - acc: 0.9915 - val_loss: 0.0512 - val_acc: 0.9850\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 600s - loss: 0.0231 - acc: 0.9928 - val_loss: 0.0330 - val_acc: 0.9908\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 659s - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0243 - val_acc: 0.9930\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 658s - loss: 0.0164 - acc: 0.9950 - val_loss: 0.0292 - val_acc: 0.9922\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 693s - loss: 0.0143 - acc: 0.9958 - val_loss: 0.0605 - val_acc: 0.9865\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 677s - loss: 0.0145 - acc: 0.9957 - val_loss: 0.0410 - val_acc: 0.9909\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 702s - loss: 0.0133 - acc: 0.9960 - val_loss: 0.0461 - val_acc: 0.9911\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 1634s - loss: 0.0120 - acc: 0.9968 - val_loss: 0.0324 - val_acc: 0.9941\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 634s - loss: 0.0125 - acc: 0.9967 - val_loss: 0.0535 - val_acc: 0.9897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818f372080>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=4, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 683s - loss: 0.0125 - acc: 0.9969 - val_loss: 0.0354 - val_acc: 0.9938\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 683s - loss: 0.0105 - acc: 0.9971 - val_loss: 0.0576 - val_acc: 0.9899\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 680s - loss: 0.0142 - acc: 0.9968 - val_loss: 0.0622 - val_acc: 0.9912\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 653s - loss: 0.0126 - acc: 0.9972 - val_loss: 0.0480 - val_acc: 0.9912\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 681s - loss: 0.0086 - acc: 0.9977 - val_loss: 0.0680 - val_acc: 0.9912\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 684s - loss: 0.0138 - acc: 0.9974 - val_loss: 0.0678 - val_acc: 0.9915\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 695s - loss: 0.0137 - acc: 0.9974 - val_loss: 0.0834 - val_acc: 0.9904\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 671s - loss: 0.0150 - acc: 0.9970 - val_loss: 0.0593 - val_acc: 0.9897\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 655s - loss: 0.0102 - acc: 0.9978 - val_loss: 0.0578 - val_acc: 0.9922\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 651s - loss: 0.0185 - acc: 0.9973 - val_loss: 0.0800 - val_acc: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818faf7c88>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=10, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Tip: \n",
    "- **Start with the over-fitting to make sure your NN architecture is complex enough to works well first, and then try to reduce your over-fitting by the methods. (not to reduce your complexity of your architecture until it is necessary)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3, \n",
    "                              height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_batches = gen.flow(X_test, y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3750/3750 [==============================] - 678s - loss: 0.0948 - acc: 0.9704 - val_loss: 0.0488 - val_acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1818fd48a20>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=1, \n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm + Data Augmentation\n",
    "\n",
    "**Reminder: BatchNormalization: after a Conv2D layer with data_format=\"channels_first\", set axis=1 in BatchNormalization **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        MaxPooling(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Norm + Data Augmentation + Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_bn_dropout():\n",
    "    model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1, 28, 28)),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        BatchNormalziation(axis=1),\n",
    "        Conv2D(64, (3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_model():\n",
    "    model = get_model_bn_dropout()\n",
    "    model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=1, verbose=2,\n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))\n",
    "    model.optimizer.lr = 0.1\n",
    "    model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=4, verbose=2,\n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))\n",
    "    model.optimizer.lr = 0.01\n",
    "    model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=12, verbose=2,\n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, steps_per_epoch=int(math.ceil(batches.n / batches.batch_size)), epochs=18, verbose=2,\n",
    "                 validation_data = test_batches, validation_steps=int(math.ceil(test_batches.n / test_batches.batch_size)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [fit_model() for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/mnist/'\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(path): os.mkdir(path)\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, mdl in enumerate(models):\n",
    "    mdl.save_weights(model_path+'cnn-mnist23-'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Weights\n",
    "\"\"\"\n",
    "models = []\n",
    "for i in range(6):\n",
    "    model = get_model_bn()\n",
    "    model.load_weights(model_path+'cnn-mnist23-'+str(i)+'.pkl')\n",
    "    models.append(model)\n",
    "models = np.array(models)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals = np.array([mdl.evaluate(X_test, y_test, batch_size=batch_size*4) for mdl in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evals.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds = np.stack([mdl.predict(X_test, batch_size=batch_size*4) for mdl in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_preds = all_preds.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#keras.metrics.categorical_accuracy(y_test, avg_preds).eval()\n",
    "\n",
    "# https://blog.keras.io/keras-as-a-simplified-interface-to-tensorflow-tutorial.html\n",
    "from keras.metrics import categorical_accuracy as accuracy\n",
    "\n",
    "acc_value = accuracy(y_test, avg_preds)\n",
    "with sess.as_default():\n",
    "    eval_result = acc_value.eval()\n",
    "    \n",
    "eval_result.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
